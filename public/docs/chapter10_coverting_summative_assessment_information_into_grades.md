## Chapter 10: Converting Summative Assessment Information into Grades
From Chapter 10 of *Strategies Classroom Assessment for Student Learning: Doing It Right – Using It Well*, Second Edition. Jan Chappuis, Rick Stiggins, Steve Chappuis, Judith Arter. Copyright © 2012 by Pearson Education. All rights reserved.

*The academic grade a student earns in a class should be determined by evidence of that student's achievement alone.* 

Teaching and learning have been a part of our experiences for as long as we have been in existence. Both can and do take place just fine without grades. As we have seen, student learning benefits from a number of instructional uses of assessment information, including effective feedback, but it seldom benefits directly from grading practices.

So why do we grade? The obvious reason is that others want and need the information to make decisions about students. Parents consistently want to see the familiar, periodic report card grades they knew as students so they know how their children are doing. Employers, other schools, athletic coaches and school advisors, scholarship committees, automobile insurance companies—the list goes on—want learning summarized in the shorthand that grades afford to make decisions that affect students' future well-being—course or program eligibility, scholarship awards, and good driver discounts among them. Few of these uses are within the teacher's control. Once a summary grade is assigned it must be able to stand alone as an accurate representation of student achievement.

Grades are gatekeepers and too often they shut students out of further learning, even when that is not our intent. In this chapter we build on the recommendations for formative and summative uses of assessment information taught in all previous chapters to ensure that our grading practices support learning to the extent possible. We also build directly on the record-keeping practices taught in Chapter 9 .

We first explore challenges inherent in assigning report card grades. Next we describe in detail three grading guidelines that will lead us to fair and accurate standards-based report card grades. Following that, we explain "number-crunching" options, including how to convert rubric scores to grades, that also affect accuracy. We then summarize all grading recommendations from Chapters 9 and 10 in a six-step process. Finally, but importantly for individual or organization professional growth, we offer a rubric for reviewing current grading practices.

**FIGURE 10.1** Keys to Quality Classroom Assessment

![](_page_351_Figure_3.jpeg)

### **Chapter 10 Learning Targets**

At the end of Chapter 10 you will know how to do the following:

- Identify the special challenges associated with effective communication using grades.
- Follow a series of guidelines for effective grading.
- Summarize evidence gathered over time into a meaningful grade.
- Convert rubric scores into grades.
- Evaluate and refine your own grading practices using the Rubric for Sound Grading Practices.

### **THE CHALLENGES OF REPORT CARD GRADING**

Our first responsibility as teachers is to ensure that grades provide an accurate reflection of all students' actual level of academic achievement. This requires that grades derive from assessments that accurately reflect clearly articulated learning targets. Our second responsibility is to minimize any negative impacts of the grading process on learning.

To start our investigation of sound grading practices, let's look at one teacher's experience in the early years of her career. As you read, think about whether her experiences parallel any of your own experiences with grading, or what you might know and do in your classroom that this teacher did not.

As a young teacher, I never had a student or parent seriously question a report card grade that I assigned. As a result, I never really had to open my gradebook to others to show all of the different colored symbols and markings, numbers and letter grades, comments, and codes that I somehow massaged (calculated is too strong a description) into a final grade. I was lucky, because had they done so, I would have been hard pressed to explain or defend a nonsystem, or my procedures for grade calculation. Although I didn't realize it fully at the time, I had no real guide for ensuring my grades were accurate, consistent, or fair, and in the end the grades I assigned were far more intuitive, subjective, and emotional than they were rational. It never occurred to me then that those grades might serve to either hinder or help someone to be a better learner. So although I never wanted to have grades be harmful, I frequently and subjectively included in the final grade all kinds of things—perpetual tardiness, good behavior, or a lack of effort on the part of a student whom I thought should be doing better, for example.

Further, everything, no matter when it happened in the semester, counted toward the final grade. I didn't think about the relative importance of the test or assignment, and I didn't differentiate between practice and final exercises or assignments. In my mind grading was divorced entirely from teaching and learning so it didn't bother me in the slightest that a student aide evaluated a large portion of student work, entered the data, and helped in figuring the grades.

Like far too many of us, this teacher did not have the opportunity to learn what are known as *sound grading practices* prior to beginning her career. With no external standards of quality or fairness to guide her, she was left to develop her own system for arriving at report card grades. Like her, many of us calculate grades by adhering to our own unique procedures and formulae. Some of us have no articulated process other than to record, average, and convert to a grade, while others use more elaborate mathematical systems to "crunch" the grade. Some electronic gradebook programs offer optional guidance in using their features to ensure fairness and accuracy, but we may not know what options are best to choose. Even with school and district policies in place, there can be as many different grading systems in a school as there are teachers.

And yet, of all the things we do as teachers, few have the potential for creating more conflict and communication problems than grading. All it takes to realize this

is to be the teacher on the explaining end in a conference with a parent who is questioning her child's surprisingly low grade. We can experience friction at report card preparation time as we calculate the grades of students who worked hard during the semester, but who achieved at a low level, resulting in what is sure to be a disappointing grade. At times like this we can be emotionally torn, worried about the impact of a low grade on the student's morale, and drawn to a subjective compromise that considers the student's individual circumstances while decreasing objectivity and accuracy.

On top of this, there is the grading challenge of finding the time to manage the wealth of information we collect daily in the classroom. We may sort through it, prioritize it, and assign weights to it, guided by sound grading principles. Or, like the teacher in our example, we may funnel the information through a process of our own making.

*Adopting the sound grading practices recommended in this chapter allows us to create accurate grades that communicate what they are intended to, that are fair to students, and that do not harm motivation or achievement.* 

And finally, we face the relatively new challenge of altering reporting systems to reflect standards-based teaching and learning. In a standards-driven environment, the goal of grading is to provide students and their parents the information that communicates specifically about student success in mastering relevant standards. Yet, even with individual state or provincial standards and the Common Core State Standards, many schools' grading systems continue to report student learning using letters or numbers that do not accurately summarize achievement of content area academic standards.

### **THREE GRADING GUIDELINES**

Everyone who uses grades to make decisions about students counts on them to be accurate—our responsibility to them and to our students is to provide as accurate a picture of learning as possible. This requires that we carefully answer three questions: "What is our purpose for grading?"; "What factors should we include in the grade?"; and "How do we combine those factors to give the truest picture possible of student achievement?"

 We offer answers to those questions in the form of three *grading guidelines* —three statements that serve as the foundation for an accurate and defensible grading system.

#### **Guideline 1: Use Grades to Communicate, Not to Motivate**

Going back to why we grade—because others need the information to make decisions about students—we may all agree that we grade to communicate about student learning. But we are also familiar with grading practices designed to motivate students toward desirable learning habits and responsible behaviors and away from undesirable ones. While it is unarguable that many students need help with their habits and behaviors, it is arguable that factoring their presence or absence into the academic grade is a satisfactory remedy.

Consider these three scenarios:

John is a very capable student who in the teacher's opinion is not performing at the level he should. His end-of-term grade is a borderline B/C. His teacher gives John a C to help him recognize that he needs to put forth more effort; in effect punishing him for not doing more, with the intent of waking him up and causing him to work harder.

Sarah is a hardworking student and she always turns everything in. Her end-ofterm grade is a borderline C/D. Her teacher raises her grade to a C to keep up her morale; in effect rewarding her for her hard work, with the intent of keeping her from being discouraged.

Your daughter has earned As and Bs on all projects, reports, and tests in one of her classes, yet receives a C as her end-of-term grade because her last report was one week late. Her teacher's policy is to subtract 10 points for each day an assignment is late as a deterrent to late work. Had your daughter's report been turned in on time, her final grade would have been a low A.
 In these examples considerations other than achievement are included in the grade with the intent of influencing behavior. When we do this, we are on shaky

**FIGURE 10.2** Three Grading Guidelines

- **1.** Use grades to communicate, not to motivate.
- **2.** Report achievement and other factors separately.
- **3.** Reflect only current level of achievement in the academic grade.

ground, for three significant reasons: (1) grades don't work well enough as motivators, (2) this practice often masks the problem rather than solving it, and (3) it interferes with the grade's ability to serve its communicative purpose. This is not to say that grades don't motivate some students—they do. The points here are these:

- We should not manipulate grades with the intent of changing behavior.
- Some of our attempted motivational uses of grades, while well-intentioned, harm students.

**IT DOESN'T WORK WELL ENOUGH.** Tinkering with grades to cause a change in behavior is not a reliable way to effect the desired change. Educators have done everything imaginable to make grades work as motivators and yet far too many students still are not putting forth the effort needed to succeed. We have no way of knowing whether students even get the message behind the manipulation of the grade. Further, no studies find that reducing grades as punishment increases effort. Instead of prompting stepped-up engagement, lowering grades more often causes students to withdraw from further learning (Guskey & Bailey, 2001). And far too many students are willing to take the lower grade rather than change their habits or behaviors.

Rank in class is another attempt to use grades as motivators. Instill a sense of competition, some believe, even with an artificial creation of winners and losers, and students will work harder and learn more. If that works at all, it only motivates the few who are at the top. And those generally aren't the ones who need it. In a learning environment that aspires to helping all students master essential competencies for success in college and the work place, we can't have major portions of our student population considering themselves losers.

*What should we do instead?* As we have described throughout this book, we can increase students' willingness to work harder in an intellectually healthy, learning-centered way through assessment *for* learning practices. Even when motivation appears to have evaporated, changing our assessment practices works far better to increase engagement than promising As or threatening Fs.

**IT MASKS THE PROBLEM.** Raising an academic grade for reasons unrelated to achievement to compensate for low scores does nothing to uncover the reasons behind the lack of sufficient progress. Why is Sarah's effort not resulting in adequate achievement? This should be a red flag, pointing to the need for investigation. When the underlying problem has not been identified and addressed, Sarah's potential for future achievement is compromised.

Lowering John's grade because of his perceived lack of attention to the quality of his work is not an instructional solution to the problem. He may not even be aware that he incurred this punishment. If we want to help students with these kinds of problems, they should be addressed directly during the learning, assignment by assignment, well in advance of report card grading time.

In general, lowering any academic grade for problems with work completion, attendance, effort, participation, or lack of academic honesty, while serving as a deterrent to some, does not tend to remediate repeat offenders.

*What should we do instead?* Address the real problems during the learning. Treat each of the desired habits and responsible behaviors as learning targets. Work as a team in your school to define each, communicate them as expectations, identify students experiencing difficulty, and develop appropriate remediation for each as well as deterring consequences that don't involve manipulating the grade.

**IT INTERFERES WITH COMMUNICATION.** Because key decisions hinge on them in the student's future, the purpose of grades must be to communicate. *Accurate, fair, and defensible academic grades communicate about student learning. Period.* The practice of assigning or altering academic grades to shape behavior results in the miscommunication of students' real levels of achievement. John, Sarah, and your daughter all *received* Cs, but each *earned* a different grade because they all showed evidence of different levels of achievement. Any motivation effect is fleeting, if it exists at all, yet the record is permanent. When we allow motivational intent to influence academic grades, we cripple the grade's ability to communicate.

Using grades as motivators to reward and punish or deter behavior is not consistent with a rigorous standards-based educational system such as that envisioned as the result of implementing the Common Core State Standards. It won't offer a distortion-free picture of level of achievement. Neither will it communicate about any of the hidden factors that may have contributed to or prevented learning. Any practice that distorts the meaning of the grade renders it meaningless as a communication tool.

*What should we do instead?* As O'Connor (2011) points out: "Grades are broken when they mix achievement and nonachievement elements. The fix is to report variables such as behaviors separately from achievement, thereby ensuring that grades reflect student achievement as accurately as possible" (p. 22 ).

 **FAQ 10.1 Zeroes**

Question:
*Why do you recommend never assigning zeroes?* 

Answer:
Averaging zeroes with other scores to calculate a midterm or quarter grade skews the grade in a way from which it can never recover, making the final grade a completely inaccurate picture of student achievement. Consider the case of a student who has taken three of four tests and attained scores of 100, 90, and 95 percent. The student missed one test and the score was entered as a zero, due to an unexcused absence. Her average is 71 percent, usually a C but sometimes a D. This grade clearly does not reflect her level of achievement. A more fair solution to the problem of missing work is to gather or use other information about student learning to fill in the gap. This student could, for instance, take the test before or after school. If we can't get other information in time, we may have to use an "Incomplete" to stand in for the grade until we can get enough information to make a stable generalization about the student's level of achievement on the course learning targets.

 **My Classroom Then and Now 10.1**
**Sara Poeppelman**
I used to …
Like many teachers, I used to give summative quizzes and tests and assignments that may or may not have assessed the most important aspects of what the students were supposed to have learned as a result of the instruction that was taking place in my classroom. If the students scored well, that was wonderful for them and if the students did not score well, too bad, and we went on with content that needed to be covered by the end of the year. Breaking down standards into meaningful targets that were useful to the students and myself rarely occurred. Formative assessment? I did not have a clue what that was either and how it could be any more useful than the summative assessments that I was already utilizing.

Grades generally reflected and favored those students who turned in assignments on time and did not really assess students' knowledge and understanding of key science concepts.

Now I …
Daily, students and I utilize learning targets to move the class toward the critical learning that will result from that day's instruction. Formative assessment is regular and ongoing. Instruction is modified as a result of formative assessments, sometimes for the whole class and sometimes differentiated for groups with specific challenges related to the formative assessment results. Feedback is now king. Students receive frequent feedback and utilize the feedback to make improvements on their work. Grades focus predominantly on student knowledge, skills, and understanding related to the learning targets, rather than being predominantly a measure of which students "played school well."

Why I changed …
I was at my first training on formative assessment practices, and this just made so much more sense than the way that I had been practicing the art and science of teaching up to that point, especially the importance of feedback rather than "grades." Up to this point in my career, one of the things that really bothered me was that students were often too concerned about their grade rather than what they were learning. As a teacher my philosophy has always been to focus on the learning, but I realized that my assessment practices were not promoting learning and it seemed that use of formative assessment and feedback would be a practical method to promote learning rather than a grade-driven focus.

What I notice as a result …
As a result of changing my assessment practices (what I assess, how I assess it, what my students or myself do as a result), I have noticed more students are engaged in the process of learning without the focus on the grade. By focusing in on the critical content and skills that I assess and reporting those to derive a final grade, rather than habits, such as turning homework in, I have significantly fewer students who have to be retained. Providing specific feedback with students on the other end attending to that feedback has helped motivate students to attempt to do better on assessments and other challenges in the future. I feel that I am now helping to develop learners who have the skills and confidence to take on challenges with intrinsic motivation rather that students who focus on the "once and done," grade and extrinsic motivation.

*Source :* Used with permission from Sara Poeppelman, high school science teacher, Lewis County Schools, Vanceburg, KY, 2011.

#### **Guideline 2: Report Achievement and Other Factors Separately**

Once we have determined that academic grades are to be calculated and assigned for the purpose of communicating level of achievement on learning targets we have been teaching, we can examine other factors we may want to track, assess, and report.

**EFFORT.** Effort is highly valued both in and beyond school because it is a necessary ingredient in learning or doing anything difficult. When students are trying hard to learn, our jobs as teachers are much easier because the students are meeting us at least halfway. Also, employers value people who work hard, who demonstrate persistence, who take initiative, and who go beyond what is required of them to make the business successful.

However, John's and Sarah's Cs tell us nothing about their very different levels of effort. If information about their effort would assist us in interpreting the grade

they were assigned, then evidence of that effort should be reported separately from the academic grade. Rarely are there explicit criteria available to judge effort. The task is made harder by the fact that students, through physical appearance or behavior, may appear either to be engaged or totally out of it, when in fact, the opposite may be true (Brookhart, 2004). Further muddying the waters, effort isn't one thing—it is a collection of behaviors and attitudes. It doesn't look the same to all teachers— different teachers may describe it differently and look for different evidence of it.

The keys to assessment quality apply here just as they do with achievement: If we wish to communicate about level of effort, we will need to define what behaviors and attitudes comprise our definition, determine how best to evaluate them accurately, determine what symbols we will use to communicate and what they will mean, and then create a separate space on the report card for our judgment.

*Define it, diagnose it, teach it, remediate it, assess it, and report it separately.*

**OTHER FACTORS.** And so it is for all other factors we might wish to take into account in figuring final grades—attendance, work completion, turning work in on time, group participation, skills of cooperation, academic honesty, or any other valued habit or behavior. If we decide that factors beyond level of achievement are important to report, we must define them, communicate our expectations to students, decide what data to collect, then collect and report it separately. Admittedly this process is initially more time consuming than lowering grades, but if factors other than achievement are import to develop in students and to report out, we can see no other way to make meaning clear.
We recommend Ken O'Connor's *A Repair Kit for Grading: 15 Fixes for Broken Grades* (O'Connor, 2011) for an in-depth treatment of how to address problems with habits and behaviors without using grades as rewards, deterrents, or punishments.

#### **Guideline 3: Reflect Only Current Level of Achievement in the Academic Grade**

In a standards-based environment, grade reports must reflect our best measure of student achievement at the time they are assigned. If more recent information about student achievement shows a higher level of learning on a given content standard or learning target, then the grade should be based on the newer evidence. Averaging the new information with the old, outdated information has the effect of lowering the grade for students who had the farthest to come and did so. It provides an incorrect picture of student achievement at that point in time and can lead to ill-informed instructional and support decisions. It also reinforces in students the notion that it's better to already know than to learn. O'Connor (2011) reminds us it's not where a student starts on a given learning target that matters, but where the student finishes.

We can also think of formative and summative assessment information in this light. The formative assessment information is data gathered about level of achievement during learning—practice, trial and error, and so forth. So we use assessments *for* learning to diagnose problems, plan further instruction, provide students with feedback, and to help them improve. Periodically, we ask them to demonstrate their level of achievement by means of summative assessments *of* learning, which are a culmination of what they have learned and comprise the most recent evidence of achievement.

The recommendation to base grades on the most current evidence of the student's level of achievement on the intended learning targets does not mean that only grades from the end of the marking period should figure into the final grade. For example, if we divide the learning targets for a social studies course into several equal segments each lasting about two weeks, we might give a summative assessment at the end of each segment. Because each summative assessment provides information on different learning targets and no content has been repeated, every summative assessment score represents the most current information on the targets covered.

### **SUMMARIZING INFORMATION**

This process picks up where we left off in Chapter 9 . As you recall, we recommended that you first decide what information will be used summatively and what will be used formatively. We discussed systems that you can use to differentiate the two in your record book. Then we presented three record-keeping guidelines: (1) Organize entries by learning represented, (2) Track information about work habits and social skills separately, and (3) Record achievement information by raw score. By following the recommendations in Chapter 9 , your data will be organized so that you can easily convert them to a common scale, weight them as desired, and combine them to arrive at one overall number.

#### **Verify Accuracy of Data**

Before we go through those steps, however, it is a good idea to review your summative data for accuracy. Discard any inaccurate information from grading records. Do not include outdated information in your grade calculations. No one has yet developed an information management and communication system that can convert inaccurate information—misinformation about a student's achievement into an accurate grade. Chapters 1 through 8 offer the guidance you need to ensure that accuracy.

**FIGURE 10.3** Process for Summarizing Information

- Verify accuracy of summative data.
- Convert record book entries to a common scale.
- Weight information as needed.
- Combine information thoughtfully.

#### **Convert Entries to a Common Scale**

Once you have identified which information you will use, you will need to convert each score to a common scale. You may have recorded summative information in a variety of forms: raw scores, percentages, rubric scores, letters, and/or other evaluative symbols.

If your entries are in the form of raw scores (number correct out of number possible) and percentages (percent correct), we recommend two traditional combination procedures. You can convert all scores to percentages or you can convert all entries to raw scores. In either case, remember to use only the most current body of information and to make sure you have enough evidence to sample the learning targets adequately.

If you have rubric scores in the mix, you will need to follow an additional procedure, explained in the section "Converting Rubric Scores to Grades" later in the chapter.

If you have letters or other symbols as summative data, you will need to go back to the underlying assessments and replace the letters or symbols with raw scores, percentages, or rubric scores.

#### **Weight Information as Needed**

If you wish to give greater weight to some assessment results than to others, you can accomplish this by multiplying those scores by a weighting factor. For instance, if one score is to count twice as much as others, the weighting factor for that score is 2. Simply multiply the score by two before moving on to the next step of combining information.

An additional consideration in applying weights to grade is the structure of the grade report. Will you figure one grade to cover all of the learning targets you taught in a subject or does your report card have separate categories within the subject? You may have set your record book so your data are tracked according to those categories, but if not, now is the time to separate them.

If you will be reporting in several categories, first apply weighting factors as desired for the data within each category. If, in addition, you must combine those grades or marks into a single summary grade, determine if and how the categories will be weighted.

#### **Combine Information Thoughtfully**

Combine information from assessments into a final grade using the appropriate measure of central tendency—mean or median—for the type of data. ( Figure 10.4 provides definitions and examples of mean and median.) We traditionally combine individual pieces of achievement evidence into a final summary by calculating the mean. When data are consistent—that is, when they fall within a narrow score

| FIGURE 10.4 Measures of Central 
![](_page_363_Picture_1.jpeg)
range—the mean will yield an accurate representation of level of achievement. But when data include extreme scores—when they span a range of score points calculating the mean will skew the resulting score, as shown in Figure 10.4 . To counter this problem, many grading experts advocate using median scores rather than mean scores to summarize achievement. O'Connor (2011) encourages us to think of this process as *determining* a grade rather than *calculating* it because the measure of central tendency must be chosen to suit the data at hand:

Grades are frequently broken (inaccurate) when they result only from the calculation of the mean in contexts where extreme scores distort; they can be repaired by considering other measures of central tendency and using professional judgment. Thus we should think and talk not about the calculation but the *determination* of grades. (p. 93 )

 **FAQ 10.2 Norm-Referenced Grading**

*Question:*
*Is it ever okay to grade on a curve?* 

*Answer:*
Assessments, grades, and report cards should reflect student attainment of established achievement targets, rather than the students' place in the rank order of the class. If a student receives a grade of B, the interpreter must understand that the B reflects attainment of a certain level of mastery of the learning targets for that subject.

Guskey (1996) advises against normative grading with the following argument: "Grading on a curve makes learning a highly competitive activity in which students compete against one another for the few scarce rewards (high grades) distributed by the teacher. Under these conditions, students readily see that helping others become successful threatens their own chances for success. As a result, learning becomes a game of winners and losers; and because the number of rewards is kept arbitrarily small, most students are forced to be losers" (p. 21 ). All students could get an A, or "Exceeds the standard," if they prove that they have learned the material at the corresponding level of mastery.

In some classrooms, grades are "curved" to spread students out along a continuum of achievement, creating an artificial and inaccurate report of actual learning. If report card grades are manipulated for motivational effect, who can possibly interpret their true meaning in terms of student achievement?

### **CONVERTING RUBRIC SCORES TO GRADES**

In Chapter 7 we established that rubrics are useful as formative assessment tools to help students understand and master complex learning targets. They can also be used summatively to assign a grade or determine level of student mastery of key standards. In this section we describe how to convert ratings from rubrics to grades or mastery levels.

To begin with, any rubrics to be used to evaluate student work for grading ( summative) purposes need to satisfy the quality criteria described in detail in Chapter 7 on performance assessment. If those standards of quality are not met, then the resulting grade is not likely to provide an accurate reflection of the student's achievement.

The transformation of rubric ratings into grades, like so much of the classroom assessment process, involves a major helping of professional judgment. The challenge is to turn a profile of several ratings for each student into a single grade in a consistent manner that ensures accuracy and complete understanding by the grade recipient. There are two ways to do this. One relies on average ratings and the other on defining patterns of ratings.

Note at the outset that these processes can be applied either in assigning a grade to (1) a summative assessment during the grading period that will later be combined with other evidence to feed into the determination of a final grade or (2) a "final exam" assessment that is the culminating demonstration of proficiency that the final grade will be based on.

 **FAQ 10.3 Counting Rubric Levels as Points**

*Question:*
*Why can't I just add up the rubric points and divide the total by the number of points possible to calculate a grade?* 

*Answer:*
This will usually result in an inaccurate depiction of student achievement because numbers in a rubric are *labels for levels*, not points earned. Calculating *percentage of points earned* doesn't accurately represent student achievement because there are too few points possible and the resulting grade won't match the description of that level on the rubric. For example, on a 5-point scale the only choices are

5/5 - 100% - A 4/5 - 80% - B or C 3/5 - 60% - F 2/5 - 40% - F 1/5 - 20% -F

The description in the rubric for 1-level work might indicate a failing level of quality, but the descriptions for 2- and 3-level work probably don't.

Likewise, on a 4-point scale the only choices are

$$\begin{array}{rcl} \mathsf{4}/\mathsf{4} = \mathsf{100}\% = \mathsf{A} \\ \mathsf{5}/\mathsf{4} = \mathsf{15}\% = \mathsf{C} \\ \mathsf{2}/\mathsf{4} = \mathsf{50}\% = \mathsf{F} \\ \mathsf{1}/\mathsf{4} = \mathsf{2}\mathsf{5}\% = \mathsf{F} \end{array}$$

You may wonder why even a single point is given for the work described at the lowest level of a rubric. Once again, the reason is that it's not a point earned; it's a *label* (as are *novice and beginning*) for a set of statements that describes novice or weak performance.

#### **Average Ratings**

For each student, calculate the average rating across the profile of scales within the rubric. The *average rating* is the total of the ratings a student received divided by the total number of ratings. What we're doing here is figuring out the typical rating by calculating an average. We want to know what the ratings tell us about how well, in general, a student performs. For grading purposes, use only the scores from work toward the end of the grading period to determine a grade for a given content
**TABLE-Students Tracking Progress by Assignment**
| FIGURE 10.5 Students Tracking Progress by Assignment |                             |                                  |  |  |  |
|----------------------------------------------------------------|-----------------------------|----------------------------------|--|--|--|
| Rubric Rating Average                                          | Logical Grade Conversion    | Logical Percentage Conversion    |  |  |  |
| 3.5– 4.0                                                       | A                           | 95%                              |  |  |  |
| 2.9–3.4                                                        | B                           | 85%                              |  |  |  |
| 2.3–2.8                                                        | C                           | 75%                              |  |  |  |
| 1.7–2.2                                                        | D                           | 65%                              |  |  |  |
| 1.6 and below                                                  | F                           | 55%                              |  |  |  |

standard because the later scores will be more representative of the student's current achievement level.

Look at the rubric and decide logically what range of average ratings would match to each grade or level of mastery. We recommend that you work with colleagues on this to make sure everyone agrees. Create a conversion table that stipulates the range for each grade. Use this table to determine the appropriate grade for each student. Figure 10.5 illustrates one way to convert *average ratings* from a four-point rubric into a summary grade and then into a percentage. (If you need to combine rubric scores with other kinds of assessment information, you will need the percentage information, as explained in the following section.)

#### **Pattern of Ratings**

The second option is to work with colleagues to fashion a means for converting profiles of ratings on each particular assessment into grades. First, for example, we decide that, to get an *A* , the preponderance of student work has to be at the highest level of ratings. So, we decide that at least 50 percent of the ratings must be 4 on a set of 4-point rubrics. From here, the team establishes the pattern of ratings needed for each of the other grades, creating a conversion table to be used consistently in assigning grades. Figure 10.6 illustrates one way to use the *pattern of ratings* option to create a conversion table for linking student scores to grades.

You will notice in both of these conversion charts that the percentages are a somewhat simplified representation of the range of scores that each grade represents. When using or reporting percentages rather than grades, we recommend that you create a more precise equation table, such as that shown in Figure 10.7 . Note that the grade-to-percentage conversions in Figures 10.5, 10.6, and 10.7 are intended as examples. We encourage you to work with colleagues to devise conversions that match your expectations. These become the preset standards you can share with students and parents to help them understand how the numbers on individual summative assessments will be used to calculate a final grade.
**TABLE-Logical Conversion Table for Patterns of Averages**
| FIGURE 10.6 Logical Conversion Table for Patterns of Averages                  |                       |                            |  |  |
|--------------------------------------------------------------------------------|-----------------------|----------------------------|--|--|
| If the student's pattern of ratings is:                                        | The logical grade is: | The logical percentage is: |  |  |
| At least 50% of the ratings are 4, and not more than 5% are lower than 3       | A                     | 95%                        |  |  |
| 75% of the ratings are 3 or better, and no more than 5% are lower than 2       | B                     | 85%                        |  |  |
| 40% of the ratings are 2 or better and no more than 5% are lower than 2        | C                     | 75%                        |  |  |
| 40% of the ratings are 2 or better and no more than 50% are lower than 2       | D                     | 65%                        |  |  |
| More than 50% of the ratings are lower than 2                                  | F                     | 50%                        |  |  |

 To set this up appropriately and apply it consistently, obviously, the underlying ratings need to provide an accurate reflection of the student's achievement and the conversion must be done consistently. This requires that each teacher possess sufficient knowledge of levels of quality represented in the rubric to assign scores accurately and consistently with other teachers.

#### **Combining Rubric Ratings with Other Assessment Information to Get a Final Grade**

To illustrate this straightforward four-step process, we'll use the scores of one student, Desmond.

- **Step 1:** Use the logical conversion tables you have created to convert the rubric scores to a logical percentage. Let's say you have done that for Desmond's rubric scores and his logical percentage is 85 percent.
- **Step 2:** For the "non-rubric" portion of the grade, compute one final percentage that represents the assessment information from other sources. Let's say you gave several selected response tests that each yielded a percent correct score. You have combined these percentages using the measure of central tendency that best fits the data and Desmond's resulting score is 93 percent.

**TABLE-Grade to Percentage Conversion Table for a Four-level Rubric**
| FIGURE 10.7 Grade to Percentage Conversion Table for a Four-level Rubric |                          |                                  |  |  |
|--------------------------------------------------------------------------|--------------------------|----------------------------------|--|--|
| Rubric Rating Average                                                    | Logical Grade Conversion | Logical Percentage Conversion    |  |  |
| 3.9–4.0                                                                  | A                        | 99                               |  |  |
| 3.7–3.8                                                                  | A                        | 95                               |  |  |
| 3.5–3.6                                                                  | A                        | 91                               |  |  |
| 3.3–3.4                                                                  | B                        | 88                               |  |  |
| 3.1–3.2                                                                  | B                        | 85                               |  |  |
| 2.9–3.0                                                                  | B                        | 81                               |  |  |
| 2.7–2.8                                                                  | C                        | 78                               |  |  |
| 2.5–2.6                                                                  | C                        | 75                               |  |  |
| 2.3–2.4                                                                  | C                        | 71                               |  |  |
| 2.1–2.2                                                                  | D                        | 68                               |  |  |
| 1.9–2.0                                                                  | D                        | 65                               |  |  |
| 1.7–1.8                                                                  | D                        | 61                               |  |  |
| 1.5–1.6                                                                  | F                        | 55                               |  |  |
| 1.3–1.4                                                                  | F                        | 48                               |  |  |
| 1.0–1.2                                                                  | F                        | 40                               |  |  |

- **Step 3:** Decide if the rubric percentage (from Step 1) will have the same weight as the non-rubric percentage (from Step 2). More? Less? Assign a weighting factor, as appropriate. Assume for Desmond's class that you want the rubric percentage to count twice as much as the non-rubric percentage. So the weighting factor for the rubric percentage is 2.
- **Step 4:** Use the weighting factor to combine the rubric percentage with the non- rubric percentage. Combine the weighted percentages to calculate a final average. In Desmond's case, it would look like this: (We'll add 85 twice because it counts twice as much.)

 (85 85 93) 3 - 263 263 3 -88%

Desmond's combined final score is 88 percent.

 Figure 10.8 summarizes the recommendations for converting rubric scores to grades.

**FIGURE 10.8** Recommendations for Converting Rubric Scores to Grades

- **1.**Don't convert rubric scores to letter grades at all if you can help it . The descriptions associated with each score point give a clearer picture of students' level of achievement.
- **2.** Use a decision rule to convert a set of rubric scores to a final grade . Look at the rubric and decide what level on the rubric describes "excellent work," "good work," "fair work," and "poor work." Then come up with a decision rule for combining the rubric scores.
- **3.** Replace out-of-date evidence with more recent evidence . Keep in mind, however, that you still need a large enough sample of work to provide a stable estimate of achievement.
- **4.** Be careful when combining rubric scores with percentage information to form a final grade. Decide how much weight the percentage and rating portions of the grade will get. Combine letter grades directly using these weights. Or use a decision rule to convert the resulting rubric grade back to a percentage and then combine the percentage with other percentage scores using your weighting scheme.

### **REPORTING THE FINAL GRADE**

Reporting the final percentage score on the report card has the benefit of preserving some detail about a student's level of achievement. But most districts require teachers to convert the academic achievement summary score to a letter or number grade or a proficiency scale.

Standards for setting cutoffs vary from district to district, school to school, and sometimes teacher to teacher. The range for an A in some places may be 94 to 100 percent, for example, and in others it may be 89 to 100 percent.

Although these differences cannot be eliminated, we can acknowledge the lack of precision they carry and work to ensure consistency in our own organizations. It is also important communicate to parents in commonsense terms the level of achievement represented by each of our report card symbols. For Example 10.1 shows a common rule for converting percentages to letter grades. You should have an agreed-on conversion rule that allows all teachers to translate summary numbers into your report card's symbols with consistency.

#### **Keep the Link to Learning Targets**

 Beyond this, keep the big communication picture in mind as you think about reporting. We began by articulating a set of achievement expectations in the form of clear learning targets; that is, by specifying the things you will need and want to communicate about. We then carefully translated these standards into high- quality assessments capable of informing you about how well each student mastered each standard. We recommended keeping achievement records by learning target. Finally we discussed summarizing the evidence of learning across assessments to determine

 **For Example 10.1 Rule for Converting Percentages to Letter Grades**  A - 97–100% C - 73–76% A - 93–96% C - 70–72% A - 90–92% D - 67–69% B - 87–89% D - 63–66% B - 83–86% D - 60–62% B - 80–82% F - 59% and below C -77–79%

a summary grade. But that grade isn't merely a summary of scores. It also is a summary of student success in mastering the underlying standards reflected in your assessments. For this reason and given the records kept, we strongly recommend that, whenever you report a grade, that report be accompanied by a listing of these standards, indicating which ones the recipient of the grade did and did not master. This link brings the reporting process full circle from expectations to achievements in very specific terms.

 **FAQ 10.4 Proficiency-based Grading**

*Question:*
*We use proficiency-based grading and we mark each assignment with a level of proficiency. That is the data we keep in our record books. How do we average levels to come up with one overall level?* 

*Answer:*
Consider keeping raw scores or percentages instead of proficiency levels on individual pieces of work. Create and use a conversion table to translate the raw scores or percentages into a proficiency level for the report card.

Making a rule to translate aggregations of proficiency levels into one "uberproficiency" level for the report card is problematic from an accuracy perspective, for the following reason. When you assign a proficiency level to each piece of evidence you will use for the summary report, you are making a subjective and perhaps arbitrary interpretation of each piece of evidence. Even if your judgments are consistent, a decision about proficiency based on one sample is likely to lead to an inaccurate conclusion. Instead, we would recommend that levels of proficiency be judged from a collection of work because such decisions benefit from a larger sample size.

#### **Make Modifications with Care for Special Needs Students**

Part of our responsibility and challenge in standards-based schools is to expose all students to an appropriate and rigorous curriculum. How we determine a final grade for students with special needs should reflect their individual progress toward the standards as specified in their individualized instructional plan (IEP) (Munk & Bursuck, 2003). For these students, as with all students, we need to make final grades criterion referenced, and have the grade indicate the level of learning attained relative to the learning goals documented in the IEP. In this context, report card grades should be accompanied by some narrative description or rating system that clearly communicates student progress toward the IEP goals (O'Connor, 2002). When such modified learning targets are the basis of grades, ensure this is clear to all parties and is incorporated into the IEP. A special needs student can receive an A for attainment of different learning targets than other students in the same classroom, if such targets are specified in advance through an IEP. We simply must be sure that everyone understands that either the learning targets have been modified or a specialized grading plan within the IEP is being applied (Brookhart, 2004).

#### **Decide Borderline Cases with Extra Evidence**

In those instances when a student's summary score lies right on the borderline between two grades, we recommend that the decision about which way to go *not* be based on consideration of nonachievement factors such as effort, but on additional evidence of learning. Some teachers keep one assessment or assignment reflective of important learning in reserve to administer for such instances. Others review the record to determine how the student performed on some of the most important assessments. Others offer extra credit that provides additional evidence of learning. Whatever you do, base your judgment on the most current evidence of achievement you have.

 **FAQ 10.5 Aptitude**

*Question:*

*What about aptitude? If a student is not capable of doing grade-level work, but we assign it anyway, should we not adjust the grading scale to take into account our estimation of that student's reduced ability? Conversely, if the work assigned is too easy for a student's ability, should we lower the grade to reflect the difference between the quality of work and what the student is capable of?* 

*Answer:*
Cizek, Fitzgerald, and Rachor (1996) report that 51 percent of teachers factor ability into their grade. Although this is a common practice, the answer has to be *no*, for two reasons.

First, there is great debate in the fields of psychology and measurement about what constitutes *intelligence* and how to gauge it. In the classroom we are not equipped with the kinds of background or tests needed to be accurate in our judgments of intelligence. We can do students great harm if we act on an inaccurate perception of their ability. But, in fact, we don't determine students' instructional needs on the basis of evidence of intelligence. Instead, we use evidence of past performance as a guide in determining which learning targets are most appropriate for a given student, and then we adjust the targets, if needed, so that the student encounters work at the right level of difficulty. If we were simply to adjust the grading scale, we would mask not only the student's true level of achievement but also a learning problem that we should address.

The second reason for not adjusting the grading scale for aptitude is that it confuses the meaning of the grade. As with effort, when a teacher raises or lowers a grade based on any information other than achievement data, the grade becomes uninterpretable. It cannot stand alone as a communicator about student learning.

#### **Involve Students**
At any time during the grading period, be sure students know how their current level of achievement compares to the standards they are expected to master.

Whenever students interpret their performance to be below what they want in their record of achievement, they can be given the opportunity to study more, learn more, and retake that assessment. This is especially crucial when the material in question is prerequisite for later learning. If the objective is to bring all students to appropriate levels of mastery of standards, anything we can do to keep students learning and wanting to succeed is worth doing.

**FIGURE 10.9** Steps in Report Card Grading
- **1.** Create a list of the learning targets you will assess during the quarter.
- **2.** Make an assessment plan for summative and formative events.
- **3.** Create, choose, and/or modify assessments.
- **4.** Record information from assessments as you give them.
- **5.** Summarize the achievement information into one score.
- **6.** Translate the summary score into the report card symbol.

### **SIX STEPS TO ACCURATE, FAIR, AND DEFENSIBLE REPORT CARD GRADES**

 To put the grading guidelines into practice and to obtain accurate, justifiable grades, we suggest following the six steps (also shown in Figure 10.9 ).

- **Step 1:** Start with learning targets. Create a list of the learning targets you will assess for grading purposes during the quarter, as described in Chapter 9 .
- **Step 2:** Make an assessment plan to include both formative and summative assessment events for each unit of study, as described in Chapter 9 .
- **Step 3:** Create, choose, and/or modify assessments, either in advance of instruction or along the way, as instruction unfolds. Verify assessments for quality, using procedures explained in Chapters 5 through 8 .
- **Step 4:** Record information from assessments as you give them. Record scores according to the learning target(s) they represent. Keep raw scores, if possible, as explained in Chapter 9 . Keep rubric scores intact in the record book, as explained in this chapter.
- **Step 5:** Summarize the achievement information into one score. Select a representative sample of most recent information for each learning target. Convert each score to a common scale, multiply any scores to be weighted by their weighting factor, and then apply the appropriate measure of central tendency to get one summary score.
- **Step 6:** Translate the summary score into the symbol used on your report card using preset criterion-based standards rather than norm-referenced standards.

### **RUBRIC TO EVALUATE GRADING PRACTICES**

Figure 10.10 presents a rubric showing each of the previous recommendations as a performance continuum that you can use to think about your own grading beliefs and practices. Instructions for using it to evaluate your own grading practices are found in Activity 10.5 at the end of this chapter.
![](_page_374_Picture_1.jpeg)
![](_page_375_Picture_1.jpeg)
![](_page_376_Picture_1.jpeg)

### **Summary**

We think at times that the pursuit of grades dominates the lives of far too many students, and that the focus on grades still adversely affects the environment of too many classrooms. However grades are used once they are given, we must be dedicated to ensuring that they communicate as clearly and accurately as possible when we create them. The issue is not whether something needs to be done about grades; the issue is what to do. The grading recommendations in this chapter reflect what we think grading practices should look like if they are to be accurate and have a chance of promoting learning.

We also believe that there is a role for professional judgment in grading. In fact, it is impossible in any grading context to leave professional judgment out of the equation. Each teacher brings to their grading practices specific knowledge about individual students and their progress toward the standards. We exercise professional judgment when deciding what content to test. We exercise professional judgment when deciding how best to convert rubric scores to grades. The goal of the recommendations in this chapter is to make an essentially subjective system as objective and defensible as possible.

One of our messages throughout this book is about the power of a classroom with an aligned system of curriculum, instruction, assessment, and reporting. By now you know it begins with clear curriculum targets aligned to standards. Teachers then clarify those

targets for students and transform them into accurate assessments. Along the way students are involved in their own assessment, record keeping, and communication about their progress toward those targets, and student learning is documented and organized in record books according to learning target and standard. Finally, student achievement is reported to parents and students relative to those same standards.

This chapter has focused largely on assigning report card grades by subject in a traditional letter- or number-based system. Often parents expect, if not demand, this form of reporting, and yet they also value the specific information that can be provided through a standards-based reporting form (Guskey, 2002). We have established here that the purpose of grades is to communicate about student achievement. The next two chapters will explore other forms of communication. As you proceed, keep the goal of standardsbased education in mind: to teach, assess, improve, and communicate about student learning in relation to academic learning standards. We can focus less of our time on providing subject area grades and still accomplish our goal if we move toward the use of rich, descriptive performance standards that provide specific information about where the student is relative to each standard. In the chapters that follow, we will provide more detail about how to gather and communicate that detail. When we do it well, the payoff is worth it for us and for our students.

### **CHAPTER 10ACTIVITIES**

End-of-chapter activities are intended to help you master the chapter's learning targets. They are designed to deepen your understanding of the chapter content, provide discussion topics for learning team meetings, and guide implementation of the practices taught in the chapter.

Forms for completing each activity appear in editable Microsoft Word format in the Chapter 10 CD file. Documents on the CD are marked with this symbol:

#### **Chapter 10 Learning Targets**

At the conclusion of Chapter 10 you will know how to do the following:

- **1.** Identify the special challenges associated with effective communication using grades.
- **2.** Follow a series of guidelines for effective grading.
- **3.** Summarize evidence gathered over time into a meaningful grade.
- **4.** Convert rubric scores into grades.
- **5.** Evaluate and refine your own grading practices using the Rubric for Sound Grading Practices.

Activity 10.1 Keep a Reflective Journal Activity 10.2 Develop Solutions Other Than Grades Activity 10.3 Analyze Steps in Your Grading Process Activity 10.4 Revisit How You Convert Rubric Scores to Grades Activity 10.5 Evaluate Your Grading Practices Activity 10.6 Reflect on Your Own Learning Activity 10.7 Select Portfolio Artifacts

##### **Activity 10.1 Keep a Reflective Journal**

Keep a record of your thoughts, questions, and any implementation activities you tried while reading Chapter 10 .

Reflective Journal Form

##### **Activity 10.2 Develop Solutions Other than Grades**

After reading the descriptions of each grading guideline in the section, "Three Grading Guidelines," turn back to Chapter 9and reread the section, "Guideline 2: Track Information about Work Habits and Social Skills Separately." Work with a partner or your team to carry out the following activity.

- **1.** Select one problem to focus on: missing work, late work, cheating, or attendance.
- **2.** List the interventions and consequences currently in place in your school for the problem.
- **3.** Identify which consequences, if any, involve lowering the grade.
- **4.** If you were to remove the "lowered-grade" consequence for the problem, what other consequences might you institute to deter students from engaging in the problem behavior? What support system might you set up to help students who have the problem? Discuss with a partner or your team. (You may also want to refer to Fixes 1, 2, 4, and 5 in O'Connor [2011].)
- **5.** Draft a classroom policy that reflects a solution to the problem other than lowering the grade.
- **6.** If your building policy allows it, introduce your draft policy to students.
- **7.** Track either informally or formally any changes in student behavior that you believe are due to the new policy.
- **8.** Share your observations with a partner or with your team.

![](_page_378_Picture_16.jpeg)

Develop Solutions Other Than Grades

##### **Activity 10.3 Analyze Steps in Your Grading Process**

After reading the section, "Six Steps to Accurate, Fair, and Defensible Report Card Grades," work independently, with a partner, or with your team to complete the following activity.

- **1.** Imagine it is the beginning of a grading period—you are going to send home grades in X number of weeks. Right now, your record book is blank. What are the steps you usually take to go from no data to a final grade? List the steps in your process.
- **2.** Mark each step to indicate your level of satisfaction with it:
    - -Works fine
    - -Could be refined
    - -Needs major work or unsure what to do
- **3.** Compare your process to the one outlined in Figure 10.9 . Where does your practice align? Where does it diverge?
- **4.** Revise your process as needed.
- **5.** Use it for the next grading period. Keep track of how well it works for you.
- **6.** Share with a partner or your team your observations about the impact the changes have made.

![](_page_379_Picture_13.jpeg)

![](_page_379_Picture_15.jpeg)

Analyze Steps in Your Grading Process Compare to Steps in Report Card Grading

##### **Activity 10.4 Revisit How You Convert Rubric Scores to Grades**

After reading the section, "Converting Rubric Scores to Grades," work independently, with a partner, or with your team to complete the following activity.

- **1.** Decide whether you will determine the grade using the *average ratings* process or *pattern of ratings* process.
- **2.** If you are using the *average ratings* process, follow the instructions in the subsection titled "Average Ratings."
- **3.** If you are using the *pattern of ratings* process, follow the instructions in the subsection titled "Pattern of Ratings."
- **4.** Discuss the following questions with a partner or your team: How does this process differ from the one you have traditionally used? What are the advantages to converting rubric scores to grades using the process you selected? Would you prefer to try the other process?

none

##### **Activity 10.5 Evaluate Your Grading Practices**

Review the Rubric for Evaluating Grading Practices ( Figure 10.10 ). Work independently, with a partner, or with your team to complete the following activity. You will need your record book or access to your electronic grade reports.

- **1.** Use the rubric to evaluate your practices for each of the seven criteria. You can either record your judgments on the evaluation form or highlight the phrases in each criterion on the rubric that most closely describe your grading practices.
- **2.** Discuss both the rubric and your self-ratings with a partner or your learning team. What changes, if any, might you want to make based on the evaluation? What might be your highest priority adjustment? What might be difficult to do? What, if any, other changes would need to occur first?

![](_page_380_Picture_14.jpeg)

Rubric for Evaluating Grading Practices

Debrief Evaluating Your Grading Practices

![](_page_380_Picture_17.jpeg)

Grading Practices Evaluation Form

##### **Activity 10.6 Reflect on Your Own Learning**

Review the Chapter 10learning targets and select one or more that represented new learning for you or struck you as most significant from this chapter. If you are working individually, write a short reflection that captures your current understanding. If you are working with a partner or a team, either discuss what you have written or use this as a discussion prompt for a team meeting.

![](_page_381_Picture_4.jpeg)

Reflect on Chapter 10 Learning

##### **Activity 10.7 Select Portfolio Artifacts**

Any of the activities from this chapter can be used as portfolio entries. Select any activity you have completed or artifacts you have created that will illustrate your competence at the Chapter 10learning targets:

- **1.** Identify the special challenges associated with effective communication using grades.
- **2.** Follow a series of guidelines for effective grading.
- **3.** Summarize evidence gathered over time into a meaningful grade.
- **4.** Convert rubric scores into grades.
- **5.** Evaluate and refine your own grading practices using the Rubric for Sound Grading Practices.

If you are keeping a reflective journal, you may want to include Chapter 10 's entry in your portfolio.

![](_page_381_Picture_15.jpeg)

Chapter 10 Portfolio Entry Cover Sheet

### **CD RESOURCES**

- 1. Activity 10 .1 Reflective Journal Form
- 2. Activity 10.2 Develop Solutions Other than Grades
- 3. Activity 10.3 Analyze Steps in Your Grading Process
- 4. Activity 10.3 Compare to Steps in Report Card Grading
- 5. Activity 10.4 Revisit How You Convert Rubric Scores to Grades
- 6. Activity 10.5 Rubric for Evaluating Grading Practices
- 7. Activity 10.5 Evaluate Your Grading Practices
- 8. Activity 10.5 Grading Practices Evaluation Form
- 9. Activity 10.5 Debrief Evaluating Your Grading Practices
- 10. Activity 10.6 Reflect on Chapter 10 Learning
- 11. Activity 10.7 Chapter 10 Portfolio Entry Cover Sheet
